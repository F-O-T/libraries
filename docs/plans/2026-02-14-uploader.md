# @f-o-t/uploader — Framework-Agnostic Upload Library

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Build a framework-agnostic file upload library with plugin system (like better-upload). Core handles validation, chunking, and progress tracking. Plugins add security, storage backends, image processing, and PDF generation.

**Architecture:** `createUploader()` factory returns an uploader instance with event-driven progress. Hook-based plugin system (beforeUpload, onChunk, afterUpload, onComplete, onError). Uses `@f-o-t/datetime` for timestamps, `@f-o-t/security` as optional peer dep for security plugin.

**Tech Stack:** TypeScript, Bun, Zod ^4.3.6, @f-o-t/datetime ^2.0.0, @f-o-t/cli, @f-o-t/config

---

## Context

**Like better-upload:** Agnostic core, hooks-based plugin system, works with any framework or server.

**FOT patterns:** Pure functions, Zod validation, plugins as subpath exports, `.npmignore`.

**File structure:**
```
libraries/uploader/
├── src/
│   ├── index.ts
│   ├── types.ts
│   ├── schemas.ts
│   ├── core/
│   │   ├── uploader.ts           # createUploader()
│   │   ├── validation.ts         # File validation
│   │   ├── chunking.ts           # Chunk splitting
│   │   └── events.ts             # Event emitter
│   └── plugins/
│       ├── security/
│       │   └── index.ts
│       ├── storage/
│       │   └── index.ts
│       ├── image/
│       │   └── index.ts
│       └── pdf/
│           └── index.ts
├── __tests__/
│   ├── uploader.test.ts
│   ├── validation.test.ts
│   ├── chunking.test.ts
│   └── plugins/
│       ├── security.test.ts
│       └── storage.test.ts
├── fot.config.ts
├── package.json
├── CHANGELOG.md
├── .npmignore
└── README.md
```

---

## Task 1: Scaffold + Types + Schemas

**Step 1: Create directory structure and config files**

```bash
mkdir -p libraries/uploader/src/{core,plugins/{security,storage,image,pdf}}
mkdir -p libraries/uploader/__tests__/plugins
```

**Step 2: Write fot.config.ts**

```typescript
// libraries/uploader/fot.config.ts
import { defineFotConfig } from "@f-o-t/config";

export default defineFotConfig({
  external: ["zod", "@f-o-t/datetime", "@f-o-t/security", "@f-o-t/pdf"],
  plugins: ["security", "storage", "image", "pdf"],
});
```

**Step 3: Write package.json**

```json
{
  "name": "@f-o-t/uploader",
  "version": "1.0.0",
  "type": "module",
  "files": ["dist"],
  "main": "./dist/index.js",
  "types": "./dist/index.d.ts",
  "exports": {
    ".": {
      "types": "./dist/index.d.ts",
      "default": "./dist/index.js"
    },
    "./plugins/security": {
      "types": "./dist/plugins/security/index.d.ts",
      "default": "./dist/plugins/security/index.js"
    },
    "./plugins/storage": {
      "types": "./dist/plugins/storage/index.d.ts",
      "default": "./dist/plugins/storage/index.js"
    },
    "./plugins/image": {
      "types": "./dist/plugins/image/index.d.ts",
      "default": "./dist/plugins/image/index.js"
    },
    "./plugins/pdf": {
      "types": "./dist/plugins/pdf/index.d.ts",
      "default": "./dist/plugins/pdf/index.js"
    }
  },
  "scripts": {
    "build": "bun x --bun fot build",
    "test": "bun x --bun fot test",
    "lint": "bun x --bun fot lint",
    "format": "bun x --bun fot format",
    "check": "bun x --bun fot check"
  },
  "dependencies": {
    "zod": "^4.3.6",
    "@f-o-t/datetime": "^2.0.0"
  },
  "peerDependencies": {
    "@f-o-t/security": "^1.0.0",
    "@f-o-t/pdf": "^0.3.0"
  },
  "peerDependenciesMeta": {
    "@f-o-t/security": { "optional": true },
    "@f-o-t/pdf": { "optional": true }
  },
  "devDependencies": {
    "@f-o-t/cli": "^1.0.1",
    "@f-o-t/config": "^1.0.3",
    "@types/bun": "latest"
  }
}
```

**Step 4: Write types.ts**

```typescript
// libraries/uploader/src/types.ts
import type { DateTime } from "@f-o-t/datetime";

export type UploaderOptions = {
  maxSize?: number;                // bytes
  maxFiles?: number;
  allowedTypes?: string[];         // ["image/*", "application/pdf"]
  chunkSize?: number;              // bytes, for chunked uploads
  plugins?: UploaderPlugin[];
};

export type UploaderPlugin = {
  name: string;
  hooks: {
    beforeUpload?: (file: UploadFile) => Promise<UploadFile | null>;
    onChunk?: (chunk: UploadChunk) => Promise<void>;
    afterUpload?: (result: UploadResult) => Promise<UploadResult>;
    onProgress?: (progress: UploadProgress) => void;
    onComplete?: (file: UploadResult) => Promise<void>;
    onError?: (error: UploadError) => Promise<void>;
  };
};

export type UploadFile = {
  id: string;
  name: string;
  size: number;
  type: string;
  data: Uint8Array | ReadableStream<Uint8Array>;
};

export type UploadChunk = {
  uploadId: string;
  index: number;
  total: number;
  data: Uint8Array;
  size: number;
};

export type UploadResult = {
  id: string;
  name: string;
  size: number;
  type: string;
  path?: string;
  url?: string;
  uploadedAt: DateTime;
  metadata?: Record<string, unknown>;
};

export type UploadProgress = {
  uploadId: string;
  loaded: number;
  total: number;
  percentage: number;
};

export type UploadError = {
  uploadId: string;
  name: string;
  message: string;
  code: string;
};

export type Uploader = {
  upload(file: UploadFile): Promise<UploadResult>;
  uploadMultiple(files: UploadFile[]): Promise<UploadResult[]>;
  abort(uploadId: string): void;
  on<E extends keyof UploaderEvents>(event: E, handler: UploaderEvents[E]): void;
  off<E extends keyof UploaderEvents>(event: E, handler: UploaderEvents[E]): void;
};

export type UploaderEvents = {
  progress: (progress: UploadProgress) => void;
  complete: (result: UploadResult) => void;
  error: (error: UploadError) => void;
};
```

**Step 5: Write schemas.ts**

```typescript
// libraries/uploader/src/schemas.ts
import { z } from "zod";

export const UploaderOptionsSchema = z.object({
  maxSize: z.number().int().positive().optional().default(10 * 1024 * 1024), // 10MB
  maxFiles: z.number().int().positive().optional().default(10),
  allowedTypes: z.array(z.string()).optional(),
  chunkSize: z.number().int().positive().optional().default(5 * 1024 * 1024), // 5MB
  plugins: z.array(z.any()).optional().default([]),
});
```

**Step 6: Commit**

```bash
git add libraries/uploader/
git commit -m "chore(uploader): scaffold @f-o-t/uploader library"
```

---

## Task 2: Core — File Validation

**Files:**
- Create: `libraries/uploader/src/core/validation.ts`
- Test: `libraries/uploader/__tests__/validation.test.ts`

**Step 1: Write failing tests**

```typescript
// libraries/uploader/__tests__/validation.test.ts
import { describe, expect, test } from "bun:test";
import { validateFile } from "../src/core/validation";

describe("validateFile()", () => {
  test("accepts valid file", () => {
    const result = validateFile(
      { id: "1", name: "test.png", size: 1024, type: "image/png", data: new Uint8Array(1024) },
      { maxSize: 10 * 1024 * 1024 },
    );
    expect(result.success).toBe(true);
  });

  test("rejects file exceeding maxSize", () => {
    const result = validateFile(
      { id: "1", name: "big.bin", size: 20 * 1024 * 1024, type: "application/octet-stream", data: new Uint8Array(0) },
      { maxSize: 10 * 1024 * 1024 },
    );
    expect(result.success).toBe(false);
  });

  test("rejects disallowed MIME type", () => {
    const result = validateFile(
      { id: "1", name: "script.js", size: 100, type: "application/javascript", data: new Uint8Array(100) },
      { maxSize: 10 * 1024 * 1024, allowedTypes: ["image/*", "application/pdf"] },
    );
    expect(result.success).toBe(false);
  });

  test("accepts wildcard MIME match", () => {
    const result = validateFile(
      { id: "1", name: "photo.jpg", size: 100, type: "image/jpeg", data: new Uint8Array(100) },
      { maxSize: 10 * 1024 * 1024, allowedTypes: ["image/*"] },
    );
    expect(result.success).toBe(true);
  });

  test("rejects empty filename", () => {
    const result = validateFile(
      { id: "1", name: "", size: 100, type: "text/plain", data: new Uint8Array(100) },
      { maxSize: 10 * 1024 * 1024 },
    );
    expect(result.success).toBe(false);
  });
});
```

**Step 2: Implement validation**

```typescript
// libraries/uploader/src/core/validation.ts
import type { UploadFile } from "../types";

type ValidationOptions = {
  maxSize: number;
  allowedTypes?: string[];
};

type ValidationResult =
  | { success: true }
  | { success: false; error: string };

function matchesMimeType(fileType: string, pattern: string): boolean {
  if (pattern === "*/*") return true;
  if (pattern.endsWith("/*")) {
    const prefix = pattern.slice(0, -2);
    return fileType.startsWith(prefix + "/");
  }
  return fileType === pattern;
}

export function validateFile(
  file: UploadFile,
  options: ValidationOptions,
): ValidationResult {
  if (!file.name || file.name.length === 0) {
    return { success: false, error: "File name is required" };
  }

  if (file.size > options.maxSize) {
    return { success: false, error: `File size ${file.size} exceeds max ${options.maxSize}` };
  }

  if (options.allowedTypes && options.allowedTypes.length > 0) {
    const allowed = options.allowedTypes.some((pattern) => matchesMimeType(file.type, pattern));
    if (!allowed) {
      return { success: false, error: `File type ${file.type} not allowed` };
    }
  }

  return { success: true };
}
```

**Step 3: Run tests, commit**

Run: `cd libraries/uploader && bun test __tests__/validation.test.ts`

```bash
git add libraries/uploader/src/core/validation.ts libraries/uploader/__tests__/validation.test.ts
git commit -m "feat(uploader): add file validation"
```

---

## Task 3: Core — Chunking

**Files:**
- Create: `libraries/uploader/src/core/chunking.ts`
- Test: `libraries/uploader/__tests__/chunking.test.ts`

**Step 1: Write failing tests**

```typescript
// libraries/uploader/__tests__/chunking.test.ts
import { describe, expect, test } from "bun:test";
import { splitIntoChunks } from "../src/core/chunking";

describe("splitIntoChunks()", () => {
  test("splits data into correct number of chunks", () => {
    const data = new Uint8Array(1000);
    const chunks = splitIntoChunks("upload-1", data, 300);
    expect(chunks.length).toBe(4); // 300+300+300+100
  });

  test("each chunk has correct metadata", () => {
    const data = new Uint8Array(500);
    const chunks = splitIntoChunks("upload-1", data, 200);
    expect(chunks[0]!.index).toBe(0);
    expect(chunks[0]!.total).toBe(3);
    expect(chunks[0]!.size).toBe(200);
    expect(chunks[2]!.size).toBe(100);
  });

  test("single chunk for small files", () => {
    const data = new Uint8Array(50);
    const chunks = splitIntoChunks("upload-1", data, 1024);
    expect(chunks.length).toBe(1);
    expect(chunks[0]!.size).toBe(50);
  });
});
```

**Step 2: Implement chunking**

```typescript
// libraries/uploader/src/core/chunking.ts
import type { UploadChunk } from "../types";

export function splitIntoChunks(
  uploadId: string,
  data: Uint8Array,
  chunkSize: number,
): UploadChunk[] {
  const totalChunks = Math.ceil(data.length / chunkSize);
  const chunks: UploadChunk[] = [];

  for (let i = 0; i < totalChunks; i++) {
    const start = i * chunkSize;
    const end = Math.min(start + chunkSize, data.length);
    const chunkData = data.slice(start, end);

    chunks.push({
      uploadId,
      index: i,
      total: totalChunks,
      data: chunkData,
      size: chunkData.length,
    });
  }

  return chunks;
}
```

**Step 3: Run tests, commit**

Run: `cd libraries/uploader && bun test __tests__/chunking.test.ts`

```bash
git add libraries/uploader/src/core/chunking.ts libraries/uploader/__tests__/chunking.test.ts
git commit -m "feat(uploader): add file chunking"
```

---

## Task 4: Core — Event Emitter

**Files:**
- Create: `libraries/uploader/src/core/events.ts`

**Step 1: Implement simple typed event emitter**

```typescript
// libraries/uploader/src/core/events.ts

export type EventMap = Record<string, (...args: any[]) => void>;

export function createEventEmitter<T extends EventMap>() {
  const listeners = new Map<keyof T, Set<Function>>();

  return {
    on<E extends keyof T>(event: E, handler: T[E]) {
      if (!listeners.has(event)) listeners.set(event, new Set());
      listeners.get(event)!.add(handler);
    },
    off<E extends keyof T>(event: E, handler: T[E]) {
      listeners.get(event)?.delete(handler);
    },
    emit<E extends keyof T>(event: E, ...args: Parameters<T[E]>) {
      listeners.get(event)?.forEach((fn) => fn(...args));
    },
  };
}
```

**Step 2: Commit**

```bash
git add libraries/uploader/src/core/events.ts
git commit -m "feat(uploader): add typed event emitter"
```

---

## Task 5: Core — createUploader()

**Files:**
- Create: `libraries/uploader/src/core/uploader.ts`
- Test: `libraries/uploader/__tests__/uploader.test.ts`

**Step 1: Write failing tests**

```typescript
// libraries/uploader/__tests__/uploader.test.ts
import { describe, expect, test } from "bun:test";
import { createUploader } from "../src/core/uploader";

describe("createUploader()", () => {
  test("creates uploader with defaults", () => {
    const uploader = createUploader();
    expect(uploader).toBeDefined();
    expect(typeof uploader.upload).toBe("function");
    expect(typeof uploader.uploadMultiple).toBe("function");
    expect(typeof uploader.on).toBe("function");
  });

  test("upload() returns result with metadata", async () => {
    const uploader = createUploader();
    const result = await uploader.upload({
      id: "test-1",
      name: "file.txt",
      size: 100,
      type: "text/plain",
      data: new Uint8Array(100),
    });
    expect(result.id).toBe("test-1");
    expect(result.name).toBe("file.txt");
    expect(result.uploadedAt).toBeDefined();
  });

  test("upload() rejects file exceeding maxSize", async () => {
    const uploader = createUploader({ maxSize: 50 });
    await expect(
      uploader.upload({
        id: "test-2",
        name: "big.bin",
        size: 100,
        type: "application/octet-stream",
        data: new Uint8Array(100),
      }),
    ).rejects.toThrow();
  });

  test("uploadMultiple() handles multiple files", async () => {
    const uploader = createUploader();
    const results = await uploader.uploadMultiple([
      { id: "1", name: "a.txt", size: 10, type: "text/plain", data: new Uint8Array(10) },
      { id: "2", name: "b.txt", size: 20, type: "text/plain", data: new Uint8Array(20) },
    ]);
    expect(results.length).toBe(2);
  });

  test("emits progress events", async () => {
    const uploader = createUploader();
    const progressEvents: any[] = [];
    uploader.on("progress", (p) => progressEvents.push(p));

    await uploader.upload({
      id: "test-3",
      name: "file.txt",
      size: 100,
      type: "text/plain",
      data: new Uint8Array(100),
    });

    expect(progressEvents.length).toBeGreaterThan(0);
  });

  test("runs plugin hooks", async () => {
    const hooksCalled: string[] = [];
    const plugin = {
      name: "test-plugin",
      hooks: {
        beforeUpload: async (file: any) => { hooksCalled.push("before"); return file; },
        afterUpload: async (result: any) => { hooksCalled.push("after"); return result; },
        onComplete: async () => { hooksCalled.push("complete"); },
      },
    };

    const uploader = createUploader({ plugins: [plugin] });
    await uploader.upload({
      id: "test-4",
      name: "file.txt",
      size: 10,
      type: "text/plain",
      data: new Uint8Array(10),
    });

    expect(hooksCalled).toContain("before");
    expect(hooksCalled).toContain("after");
    expect(hooksCalled).toContain("complete");
  });
});
```

**Step 2: Implement createUploader**

```typescript
// libraries/uploader/src/core/uploader.ts
import { now } from "@f-o-t/datetime";
import { UploaderOptionsSchema } from "../schemas";
import type { Uploader, UploaderEvents, UploaderOptions, UploadFile, UploadResult } from "../types";
import { validateFile } from "./validation";
import { splitIntoChunks } from "./chunking";
import { createEventEmitter } from "./events";

export function createUploader(options?: Partial<UploaderOptions>): Uploader {
  const opts = UploaderOptionsSchema.parse(options ?? {});
  const emitter = createEventEmitter<UploaderEvents>();
  const abortControllers = new Map<string, AbortController>();

  async function runPluginHook<K extends string>(
    hookName: K,
    ...args: any[]
  ): Promise<any> {
    let result = args[0];
    for (const plugin of opts.plugins) {
      const hook = (plugin.hooks as any)[hookName];
      if (typeof hook === "function") {
        const hookResult = await hook(result, ...args.slice(1));
        if (hookResult !== undefined && hookResult !== null) {
          result = hookResult;
        }
      }
    }
    return result;
  }

  async function processUpload(file: UploadFile): Promise<UploadResult> {
    // Validate
    const validation = validateFile(file, {
      maxSize: opts.maxSize,
      allowedTypes: opts.allowedTypes,
    });
    if (!validation.success) {
      const error = { uploadId: file.id, name: file.name, message: validation.error, code: "VALIDATION_ERROR" };
      await runPluginHook("onError", error);
      emitter.emit("error", error);
      throw new Error(validation.error);
    }

    // Run beforeUpload hooks
    const processedFile = await runPluginHook("beforeUpload", file);
    if (processedFile === null) {
      throw new Error("Upload cancelled by plugin");
    }

    // Get data as Uint8Array
    let data: Uint8Array;
    if (processedFile.data instanceof Uint8Array) {
      data = processedFile.data;
    } else {
      // Read stream
      const reader = processedFile.data.getReader();
      const chunks: Uint8Array[] = [];
      let done = false;
      while (!done) {
        const result = await reader.read();
        done = result.done;
        if (result.value) chunks.push(result.value);
      }
      const totalLength = chunks.reduce((sum, c) => sum + c.length, 0);
      data = new Uint8Array(totalLength);
      let offset = 0;
      for (const chunk of chunks) {
        data.set(chunk, offset);
        offset += chunk.length;
      }
    }

    // Process chunks
    const chunks = splitIntoChunks(file.id, data, opts.chunkSize);
    for (const chunk of chunks) {
      await runPluginHook("onChunk", chunk);

      // Emit progress
      const loaded = (chunk.index + 1) * opts.chunkSize;
      const progress = {
        uploadId: file.id,
        loaded: Math.min(loaded, file.size),
        total: file.size,
        percentage: Math.min(Math.round((loaded / file.size) * 100), 100),
      };
      await runPluginHook("onProgress", progress);
      emitter.emit("progress", progress);
    }

    // Build result
    let result: UploadResult = {
      id: file.id,
      name: file.name,
      size: file.size,
      type: file.type,
      uploadedAt: now(),
    };

    // Run afterUpload hooks
    result = await runPluginHook("afterUpload", result);

    // Run onComplete hooks
    await runPluginHook("onComplete", result);
    emitter.emit("complete", result);

    return result;
  }

  return {
    async upload(file: UploadFile): Promise<UploadResult> {
      return processUpload(file);
    },

    async uploadMultiple(files: UploadFile[]): Promise<UploadResult[]> {
      if (files.length > opts.maxFiles) {
        throw new Error(`Too many files: ${files.length} exceeds max ${opts.maxFiles}`);
      }
      return Promise.all(files.map((f) => processUpload(f)));
    },

    abort(uploadId: string) {
      abortControllers.get(uploadId)?.abort();
      abortControllers.delete(uploadId);
    },

    on: emitter.on.bind(emitter),
    off: emitter.off.bind(emitter),
  };
}
```

**Step 3: Run tests, commit**

Run: `cd libraries/uploader && bun test __tests__/uploader.test.ts`

```bash
git add libraries/uploader/src/core/uploader.ts libraries/uploader/__tests__/uploader.test.ts
git commit -m "feat(uploader): add createUploader() with plugin hooks and progress"
```

---

## Task 6: Security Plugin

**Files:**
- Create: `libraries/uploader/src/plugins/security/index.ts`
- Test: `libraries/uploader/__tests__/plugins/security.test.ts`

**Step 1: Implement security plugin**

```typescript
// libraries/uploader/src/plugins/security/index.ts
import type { UploaderPlugin, UploadFile } from "../../types";

export type SecurityPluginOptions = {
  sanitizeFilename?: boolean;
  maxFilenameLength?: number;
  blockDotFiles?: boolean;
  blockDoubleExtensions?: boolean;
  dangerousExtensions?: string[];
};

const DEFAULT_DANGEROUS = [".exe", ".bat", ".cmd", ".com", ".msi", ".sh", ".ps1"];

export function securityPlugin(options?: SecurityPluginOptions): UploaderPlugin {
  const opts = {
    sanitizeFilename: true,
    maxFilenameLength: 255,
    blockDotFiles: true,
    blockDoubleExtensions: true,
    dangerousExtensions: DEFAULT_DANGEROUS,
    ...options,
  };

  return {
    name: "security",
    hooks: {
      async beforeUpload(file: UploadFile): Promise<UploadFile> {
        let name = file.name;

        // Block dotfiles
        if (opts.blockDotFiles && name.startsWith(".")) {
          throw new Error(`Dotfiles not allowed: ${name}`);
        }

        // Check dangerous extensions
        const ext = name.slice(name.lastIndexOf(".")).toLowerCase();
        if (opts.dangerousExtensions.includes(ext)) {
          throw new Error(`Dangerous file extension: ${ext}`);
        }

        // Block double extensions (e.g., file.php.jpg)
        if (opts.blockDoubleExtensions) {
          const parts = name.split(".");
          if (parts.length > 2) {
            const secondExt = "." + parts[parts.length - 2]!.toLowerCase();
            if (opts.dangerousExtensions.includes(secondExt)) {
              throw new Error(`Dangerous double extension detected: ${name}`);
            }
          }
        }

        // Sanitize filename
        if (opts.sanitizeFilename) {
          name = name
            .replace(/[^\w.\-]/g, "_")   // Replace unsafe chars
            .replace(/\.{2,}/g, ".")     // Remove consecutive dots
            .slice(0, opts.maxFilenameLength);
        }

        return { ...file, name };
      },
    },
  };
}
```

**Step 2: Run tests, commit**

```bash
git add libraries/uploader/src/plugins/security/ libraries/uploader/__tests__/plugins/security.test.ts
git commit -m "feat(uploader): add security plugin"
```

---

## Task 7: Storage Plugin

**Files:**
- Create: `libraries/uploader/src/plugins/storage/index.ts`
- Test: `libraries/uploader/__tests__/plugins/storage.test.ts`

**Step 1: Implement storage plugin**

```typescript
// libraries/uploader/src/plugins/storage/index.ts
import * as fs from "node:fs/promises";
import * as path from "node:path";
import type { UploaderPlugin, UploadResult, UploadChunk } from "../../types";

export type StorageOptions =
  | { type: "local"; basePath: string; createDirs?: boolean }
  | { type: "custom"; handler: (name: string, data: Uint8Array) => Promise<string> };

export function storagePlugin(options: StorageOptions): UploaderPlugin {
  const fileBuffers = new Map<string, Uint8Array[]>();

  return {
    name: "storage",
    hooks: {
      async onChunk(chunk: UploadChunk) {
        if (!fileBuffers.has(chunk.uploadId)) {
          fileBuffers.set(chunk.uploadId, []);
        }
        fileBuffers.get(chunk.uploadId)!.push(chunk.data);
      },

      async afterUpload(result: UploadResult): Promise<UploadResult> {
        const chunks = fileBuffers.get(result.id) ?? [];
        const totalSize = chunks.reduce((sum, c) => sum + c.length, 0);
        const combined = new Uint8Array(totalSize);
        let offset = 0;
        for (const chunk of chunks) {
          combined.set(chunk, offset);
          offset += chunk.length;
        }
        fileBuffers.delete(result.id);

        if (options.type === "local") {
          const filePath = path.join(options.basePath, result.name);
          if (options.createDirs) {
            await fs.mkdir(path.dirname(filePath), { recursive: true });
          }
          await fs.writeFile(filePath, combined);
          return { ...result, path: filePath };
        }

        if (options.type === "custom") {
          const url = await options.handler(result.name, combined);
          return { ...result, url };
        }

        return result;
      },
    },
  };
}
```

**Step 2: Run tests, commit**

```bash
git add libraries/uploader/src/plugins/storage/ libraries/uploader/__tests__/plugins/storage.test.ts
git commit -m "feat(uploader): add storage plugin (local + custom)"
```

---

## Task 8: Index + Documentation + Release

**Files:**
- Create: `libraries/uploader/src/index.ts`
- Create: `libraries/uploader/README.md`
- Create: `libraries/uploader/CHANGELOG.md`
- Create: `libraries/uploader/.npmignore`

**Step 1: Write index.ts**

```typescript
// libraries/uploader/src/index.ts
export type {
  Uploader, UploaderOptions, UploaderPlugin, UploaderEvents,
  UploadFile, UploadResult, UploadProgress, UploadChunk, UploadError,
} from "./types";

export { UploaderOptionsSchema } from "./schemas";
export { createUploader } from "./core/uploader";
export { validateFile } from "./core/validation";
export { splitIntoChunks } from "./core/chunking";
```

**Step 2: Write CHANGELOG, README, .npmignore**

**Step 3: Build and run all tests**

Run: `cd libraries/uploader && bun x --bun fot build && bun test`

**Step 4: Commit**

```bash
git add -A libraries/uploader/
git commit -m "feat(uploader): complete @f-o-t/uploader v1.0.0

Framework-agnostic upload with plugin system, chunking, validation, progress."
```
